{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./wiki_list_corpus_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./wiki_list_corpus_builder.py\n",
    "# Jesse Bacon 6/28/15\n",
    "# This will output a pickle that can be loaded and contatins a comprehensive list\n",
    "# of usefull lists from Wikipedia.  It is usefull as a text corpus for neuro linguistic\n",
    "# exercies, text processing, and training a lexical classifier or language emulator\n",
    "# I don't know.  Um.\n",
    "\n",
    "import wikipedia, re, pickle\n",
    "\n",
    "list_of_lists = {}\n",
    "category_names = []\n",
    "categories = []\n",
    "page = wikipedia.page('List of lists of lists')\n",
    "content = page.content\n",
    "i = 0\n",
    "\n",
    "def build_list_data(content):\n",
    "    all_list_data = content.splitlines()\n",
    "    for line in all_list_data:\n",
    "        if line == '':\n",
    "            all_list_data.remove(line)\n",
    "    all_list_data = all_list_data[1:]\n",
    "    for line in all_list_data:\n",
    "        #I had to put these in\n",
    "        re.sub( r'\\xe2\\x80\\x9308|\\xe2\\x80\\x9310|\\xe2\\x80\\x9309', '', line )\n",
    "        re.sub( r'(1966\\u20132001)', '1966-2001', line  )\n",
    "        re.sub( 'r\\u2013', '', line )\n",
    "        if line.startswith('Lists of tenants in the World Trade Center'):\n",
    "            line.replace(line, 'Lists of tenants in the World Trade Center (1966-2001)')\n",
    "        if line.endswith('World Trade Center (1966\\u20132001)'):\n",
    "            line.repace(line, 'Lists of tenants in the World Trade Center (1966-2001)' )\n",
    "        #for me it will not sub.  Perhaps I need to change the encoding\n",
    "        if line.startswith('Lists of tenants in the World Trade Center'):\n",
    "            line.encode('ascii', 'ignore').decode('ascii', 'ignore')\n",
    "        #I defer here.  Somethings up.  \n",
    "    return all_list_data\n",
    "\n",
    "def build_categories(all_list_data):\n",
    "    for line in all_list_data:\n",
    "        if line.startswith('='):\n",
    "            categories.append(line)\n",
    "    return categories\n",
    "\n",
    "def assemble_dict(categories):\n",
    "    for category in categories:\n",
    "        cat_name = re.sub('\\s|\\n|=', '', category.lower())\n",
    "        #print(cat_name)\n",
    "        category_names.append(cat_name)\n",
    "        list_of_lists[cat_name] = []\n",
    "\n",
    "def populate_dict(lists_page):\n",
    "    for line in lists_page:\n",
    "        if line == '' :\n",
    "            lists_page.remove(line)\n",
    "        if line.startswith('='):\n",
    "            current_category = re.sub( '\\s|=', '', line ).lower()\n",
    "            #print(current_category)\n",
    "        else:\n",
    "            text = re.sub(r'\\n', '', line)\n",
    "            text = re.sub(r'\\xe2\\x80\\x9308|\\xe2\\x80\\x9310|\\xe2\\x80\\x9309', '', text)\n",
    "            list_of_lists[current_category].append(text)\n",
    "\n",
    "def recurse_lists_level_1(list_of_lists):\n",
    "    for category in list_of_lists.keys():\n",
    "        print category\n",
    "        recurse = {}\n",
    "        print('######   ' + category + '   ######')\n",
    "        for page in list_of_lists[category]:\n",
    "            if i<1:\n",
    "                try:\n",
    "                    print(page)\n",
    "                    fetch = wikipedia.page(page)\n",
    "                    content = fetch.content\n",
    "                    recurse[page] = content\n",
    "                except:\n",
    "                    print('Could not fetch %s' % page)\n",
    "        list_of_lists[category] = recurse\n",
    "\n",
    "def save_big_dict_pickle(bd_name):\n",
    "    pickle.dump(list_of_lists, open( bd_name, 'wb'))\n",
    "\n",
    "def load_big_dict_pickle(bd_file):\n",
    "    return pickle.load( open( bd_file, 'rb') )\n",
    "    \n",
    "lists_page = build_list_data(content)\n",
    "categories = build_categories(lists_page)\n",
    "assemble_dict(categories)\n",
    "populate_dict(lists_page)\n",
    "bigDictWikiLists = recurse_lists_level_1(list_of_lists)\n",
    "save_big_dict_pickle('test.pickle')\n",
    "db = load_big_dict_pickle('test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
